---
nav_order: 70
parent: 프로젝트
title: '[DONE] 003-3 - Long/Short Gate 분리: 노이즈 강건 학습'
description: "Long/Short Gate 2-헤드 구조. 노이즈 강건 손실 함수(Bootstrapped BCE, Self-paced BCE). PR-AUC, Precision@K 평가 중심."
---

# 003-3 - Long/Short Gate 분리: 노이즈 강건 학습
{:.no_toc}

## 목차
{:.no_toc}

1. TOC
{:toc}

---

| 상태 | 생성일 | 수정일 |
|------|--------|--------|
| completed | 2025-12-22 | 2025-12-23 |

---

## Goal

기존 multi-head 구조(cls_close, reg, gate, action)를 **Long Gate + Short Gate 2-head 구조로 단순화**하고, **라벨 노이즈에 강건한 손실 함수**를 적용하여 예측 가능한 희귀 패턴(~1%)만 높은 precision으로 탐지한다.

- 기존 cls_close (3-bin 분류), reg (회귀) 헤드 **전부 제거**
- 모델 목적을 "가격 예측"에서 **"거래 기회 탐지"로 명확히 전환**

## Background

### 문제 구조 (핵심)

- "특이 케이스"(long/short 조건 충족)가 전체의 약 **10%**
- 그 중 **입력 시계열 패턴으로 예측 가능한 양성은 약 1%**
- 나머지 **약 9%는 입력과 독립적으로(무작위처럼) 발생**
- 즉, 라벨 기준으로는 양성(1)이지만 **예측 불가능한 양성(노이즈)이 대다수**인 **강한 라벨 노이즈/혼합 분포** 문제

### 기대치와 현실적 목표

- 9%가 무작위라면 모델이 아무리 좋아도 원리적으로 맞추기 어려움 (베이즈 한계)
- **목표**: "10% 전체 양성 맞추기"가 아니라, **설명 가능한 1%만 높은 precision으로 건지는 선택적 탐지**
- **평가/운영**: threshold를 올려 알람(거래) 수를 제한하고, precision 중심으로 평가

### 003-1 (기존 구조)의 한계

- Gate: 거래 여부만 결정 (binary)
- Action: 거래 시 방향 결정 (NO_TRADE/LONG/SHORT)
- 문제점: Gate, Action 둘 다 제대로 학습 안됨

## Scope

### 제거 작업
- [x] cls_close 헤드 제거 (3-bin 분류)
- [x] reg 헤드 제거 (회귀)
- [x] gate, action 헤드 제거
- [x] 관련 상수 제거: LAMBDA_CLS, LAMBDA_REG, LAMBDA_GATE, LAMBDA_ACTION
- [x] 관련 라벨 생성 로직 제거: cls_y, reg_y, gate_y, action_y

### 추가 작업
- [x] long_gate, short_gate 헤드 추가
- [x] 상수 추가: LAMBDA_LONG_GATE, LAMBDA_SHORT_GATE
- [x] 라벨 생성 로직 추가: long_gate_y, short_gate_y
- [x] 학습 파이프라인 수정: 손실함수, metrics, 파라미터 전달
- [x] 평가 메트릭 구현: PR-AUC, Precision@K, coverage 중심

### 손실 함수 구현
- [x] **Baseline BCE**: 순수 BCE 구현
- [x] **Self-paced Loss**: 구현 (percentile=70, warmup=5)
- [x] **Bootstrapped BCE**: 구현 (beta=0.8)

### 손실 함수 실험 (순차 진행) - 미완료
1. [ ] **Baseline**: BCE 학습 및 성능 기록
   - threshold 튜닝으로 precision 확인
   - 베이스라인 성능 기록
2. [ ] **Self-paced Loss**: 학습 및 Baseline 대비 비교
   - percentile=70, warmup=5 epochs
3. [ ] **Bootstrapped BCE**: 학습 및 비교
   - beta=0.8 → 0.7 → 0.6 순으로 실험
4. [ ] 최종 손실 함수 선택 및 threshold 세부 튜닝

## Technical Details

### 라벨 정의

```python
# 가격 변수
open_price = base_close[i]  # 현재 시점 종가 = 진입가
max_price = base_high[i+1:future_idx+1].max()  # 기간 내 최고가
min_price = base_low[i+1:future_idx+1].min()   # 기간 내 최저가

upside = max_price - open_price
downside = open_price - min_price
upside_pct = upside / open_price
downside_pct = downside / open_price

# Long Gate: 상승이 하락의 2배 AND 상승률 1% 이상
long_gate_y = ((upside > downside * 2) & (upside_pct > 0.01))

# Short Gate: 하락이 상승의 2배 AND 하락률 1% 이상
short_gate_y = ((downside > upside * 2) & (downside_pct > 0.01))
```

### 모델 구조

**기존 (제거 대상):**
```
Input → LSTM → Shared Dense → {cls_close, reg, gate, action}
```

**변경 후:**
```
Input → LSTM → Shared Dense → {long_gate, short_gate}
```

- **2개 출력만** (cls_close, reg, gate, action 모두 제거)
- 각 gate는 sigmoid binary head:
  - `p_long = sigmoid(W_long @ h + b_long)`
  - `p_short = sigmoid(W_short @ h + b_short)`
- 추론 시 `p > τ` 형태로 각 gate를 독립적으로 발동 (τ는 precision 목표에 맞춰 튜닝)

### 손실 함수: 노이즈 강건 설계

#### 왜 기본 Focal Loss가 위험한가

- Focal loss는 "어려운 샘플(계속 틀리는 샘플)"에 가중치를 키움
- 이 문제에서는 **예측 불가능한 양성(랜덤 9%)이 영원히 어려운 샘플로 남기 쉬워서**, focal이 그 9%를 더 강하게 쫓게 만들고 학습이 흔들리거나 패턴(1%)이 묻힐 수 있음

#### 옵션 A: Bootstrapped BCE (권장)

양성 라벨을 100% 신뢰하지 않고 일부를 모델 예측과 섞어 노이즈 충격을 완화.

```python
def bootstrapped_bce(y_true, y_pred, beta=0.8):
    """
    beta: 라벨 신뢰도 (1.0 = 순수 BCE, 0.5 = 50% 모델 예측 혼합)

    직관: "계속 말 안 맞는(랜덤) 양성"을 끝까지 억지로 끌지 않게 해서
    패턴형 1%의 일관된 신호가 상대적으로 부각
    """
    # soft label: 라벨과 모델 예측의 가중 평균
    y_soft = beta * y_true + (1 - beta) * y_pred

    # BCE with soft labels
    loss = -y_soft * tf.math.log(y_pred + 1e-7) \
           - (1 - y_soft) * tf.math.log(1 - y_pred + 1e-7)
    return tf.reduce_mean(loss)
```

#### 옵션 B: Self-paced Loss Truncation (권장)

학습 중 loss가 큰 양성(대개 랜덤)을 자동으로 다운웨이트/제외.

```python
def self_paced_bce(y_true, y_pred, percentile=70, warmup_epochs=5, current_epoch=0):
    """
    percentile: loss 상위 몇 %를 제외할지 (예: 70 = 상위 30% 제외)
    warmup_epochs: 초반에는 순수 BCE로 워밍업

    직관: 모델이 먼저 맞추기 시작하는(=loss가 빨리 내려가는)
    패턴형 양성을 중심으로 학습이 진행되어 안정적
    """
    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)

    if current_epoch < warmup_epochs:
        return tf.reduce_mean(bce)

    # loss threshold 계산
    threshold = tfp.stats.percentile(bce, percentile)

    # threshold 이하만 학습에 사용
    mask = tf.cast(bce <= threshold, tf.float32)
    return tf.reduce_sum(bce * mask) / (tf.reduce_sum(mask) + 1e-7)
```

#### 옵션 C: Weighted BCE (신중히 사용)

- 양성 비율(10%)만 보고 `pos_weight≈9`로 크게 주면 **랜덤 양성까지 강하게 맞추도록 압박**할 수 있음
- pos_weight는 **9보다 작게(예: 2~5)**부터 튜닝하고, 나머지는 threshold로 precision을 맞추는 전략이 안전

```python
# 주의: pos_weight는 낮게 시작
loss = tf.keras.losses.BinaryCrossentropy(
    from_logits=False
)
# sample_weight로 조절: pos_weight=3 정도로 시작
```

### 최종 손실 함수 구성

```python
# 기존 (제거)
# loss = {
#     'cls_close': 'categorical_crossentropy',
#     'reg': 'mae',
#     'gate': 'binary_crossentropy',
#     'action': 'categorical_crossentropy',
# }

# 변경 후: 2개 헤드만
loss = {
    'long_gate': self_paced_bce(percentile=70),   # 권장
    'short_gate': self_paced_bce(percentile=70),
}

loss_weights = {
    'long_gate': LAMBDA_LONG_GATE,    # 1.0
    'short_gate': LAMBDA_SHORT_GATE,  # 1.0
}
```

### 평가 메트릭

**핵심 원칙**: Accuracy보다 **PR-AUC, Precision@K, coverage(발동률)** 중심

```python
trading_metrics = {
    'long_gate': {
        'pr_auc': float,        # Precision-Recall AUC (핵심)
        'precision_at_k': {     # 상위 K%에서의 precision
            '1%': float,
            '5%': float,
            '10%': float,
        },
        'coverage': float,      # p > τ 비율 (발동률)
        'precision': float,     # τ 기준
        'recall': float,        # τ 기준
        'avg_pnl': float,       # max_return 기반
        'hit_rate': float,
    },
    'short_gate': {
        'pr_auc': float,
        'precision_at_k': {
            '1%': float,
            '5%': float,
            '10%': float,
        },
        'coverage': float,
        'precision': float,
        'recall': float,
        'avg_pnl': float,       # min_return 기반
        'hit_rate': float,
    },
    'combined': {
        'total_coverage': float,
        'conflict_rate': float,  # long=1 & short=1 비율
    }
}
```

#### 메트릭 상세 설명

**기본 정보**

| 항목 | 설명 |
|------|------|
| Samples | 평가에 사용된 총 샘플 수 (15분 간격 데이터 포인트) |
| Threshold | 게이트 활성화 임계값 (기본 GATE_THRESHOLD) - 예측 확률이 이 값 초과시 신호 발생 |

**Long Gate / Short Gate 메트릭**

| 항목 | 설명 |
|------|------|
| Label ratio | 실제 양성 비율. 예: 30%면 전체 중 30%가 실제 롱/숏 기회였음 |
| PR-AUC | Precision-Recall AUC. 불균형 데이터에서 모델 성능 측정. 1에 가까울수록 좋음 |
| Coverage | 모델이 신호를 발생시킨 비율. 예: 10%면 전체 중 10%에서 거래 신호 발생 |
| Precision | 정밀도. 신호 발생 중 실제 기회였던 비율. TP / (TP + FP) |
| Recall | 재현율. 실제 기회 중 모델이 찾아낸 비율. TP / (TP + FN) |
| F1 | Precision과 Recall의 조화평균. 균형 잡힌 성능 지표 |
| Precision@K% | 상위 K% 확률 예측에서의 정밀도. 가장 확신 있는 신호의 품질 |
| Avg PnL | 신호 발생 시점의 평균 수익률 (%). 실제 거래 시 기대 수익 |
| Hit Rate | 신호 발생 중 양의 수익을 낸 비율 (승률) |
| PnL@K% | 상위 K% 확률 예측의 평균 수익률 (%). 고확신 신호의 수익성 |

**Combined 메트릭**

| 항목 | 설명 |
|------|------|
| Total Coverage | 롱 또는 숏 중 하나라도 신호가 발생한 비율 |
| Conflict Rate | 롱과 숏이 동시에 신호를 발생시킨 비율 (낮을수록 좋음) |
| Conflict Count | 충돌 발생 횟수 |

### Threshold 튜닝 전략

```python
def find_optimal_threshold(y_true, y_pred, target_precision=0.5):
    """
    목표 precision을 달성하는 최소 threshold 찾기

    운영 가정: 높은 precision + 제한된 coverage
    """
    for tau in np.arange(0.5, 0.99, 0.01):
        preds = (y_pred > tau).astype(int)
        if preds.sum() == 0:
            continue
        precision = precision_score(y_true, preds)
        if precision >= target_precision:
            coverage = preds.mean()
            return tau, precision, coverage
    return None
```

## Acceptance Criteria

- [x] 기존 헤드 완전 제거 (cls_close, reg, gate, action)
- [x] 모델이 **2개 출력만** 생성 (long_gate, short_gate)
- [x] 각 gate가 독립적 binary classification 수행
- [x] Self-paced Loss 구현 및 적용
- [x] Long gate와 Short gate가 동시에 1인 경우 (conflict) 로깅
- [x] 각 gate별 PR-AUC, Precision@K(1%, 5%, 10%), coverage 계산
- [x] Threshold 튜닝 유틸리티 구현
- [x] Python syntax 검증 통과

## Implementation Notes

### 제거되는 상수

```python
# 제거 대상
LAMBDA_CLS = ...      # 삭제
LAMBDA_REG = ...      # 삭제
LAMBDA_GATE = ...     # 삭제
LAMBDA_ACTION = ...   # 삭제
```

### 권장 하이퍼파라미터 시작점

```python
# Self-paced Loss (권장)
LOSS_PERCENTILE = 70  # 상위 30% loss 제외
WARMUP_EPOCHS = 5     # 초반 5 epoch는 순수 BCE

# Threshold (추론 시)
INITIAL_TAU = 0.7     # 높게 시작해서 precision 확보

# Loss weights (유일한 2개)
LAMBDA_LONG_GATE = 1.0
LAMBDA_SHORT_GATE = 1.0
```

### 실험 순서 권장

1. **Baseline**: 순수 BCE + threshold 튜닝
2. **Bootstrapped BCE**: beta=0.8 → 0.7 → 0.6 순으로 실험
3. **Self-paced**: percentile=70 → 60 → 80 순으로 실험
4. 최종 선택 후 threshold 세부 튜닝

## Related

- [003-1-selective-trading-gate-action](003-1-selective-trading-gate-action.md) - 선행 작업 (제거 대상)
- [003-2-simplify-prediction-heads](003-2-simplify-prediction-heads.md) - 헤드 단순화 작업

## Related Files

- `src/prediction/prediction_model.py`
  - 상수 정의 (lines 67-76)
  - `parse_training_features()` (lines 490-617)
  - `create_model_lstm()` (lines 1264-1301)
  - `_split_train_val()` (lines 1303-1354)
  - `_train_model()` (lines 1356-1462)
  - `run_training()` (lines 1477-1530)
  - `run_evaluation()` (lines 1700-2000)

---

## Implementation Results

### Changed Files
| File | Changes |
|------|---------|
| `src/prediction/prediction_model.py` | Complete refactor: removed 4-head structure (cls_close, reg, gate, action), added 2-head structure (long_gate, short_gate). Implemented 3 loss functions (BCE, Bootstrapped BCE, Self-paced BCE). Added comprehensive evaluation metrics (PR-AUC, Precision@K, coverage, hit_rate, avg_pnl). Updated training, inference, and evaluation pipelines. |
| `src/prediction/prediction_model.py` | **(2025-12-23)** Added `PeriodicCheckpoint` callback to save weights every 10 epochs. PnL calculation: simple 1:1 comparison (`upside > downside` for long, `downside > upside` for short) to determine win/lose. |

### Key Implementation Details

**New Constants:**
```python
GATE_UPSIDE_RATIO = 2.0
GATE_DOWNSIDE_RATIO = 2.0
GATE_MIN_RETURN_PCT = 0.01
LAMBDA_LONG_GATE = 1.0
LAMBDA_SHORT_GATE = 1.0
LOSS_PERCENTILE = 70
WARMUP_EPOCHS = 5
GATE_THRESHOLD = 0.5
```

**Loss Function Selection via `loss_type` parameter:**
- `'bce'`: Standard binary cross-entropy (baseline)
- `'bootstrapped'`: Bootstrapped BCE with soft labels (beta=0.8)
- `'self_paced'`: Self-paced BCE with loss truncation (percentile=70, warmup=5)

**Evaluation Metrics per Gate:**
- PR-AUC, Precision@K (1%, 5%, 10%)
- Coverage, Precision, Recall, F1
- Avg PnL, Hit Rate, PnL@K

**Periodic Checkpoint (2025-12-23):**
- Saves weights every 10 epochs during training
- Filename format: `{timestamp}_{epoch}_lg_auc_{auc}_sg_auc_{auc}_{loss_type}.weights.h5`
- Enables model selection from intermediate checkpoints

**Realistic PnL Calculation (2025-12-23):**
- Long: `upside > downside` → win (+upside_pct), else lose (-downside_pct)
- Short: `downside > upside` → win (+downside_pct), else lose (-upside_pct)
- Simple 1:1 comparison to determine win/lose outcome

### Test Results
- Python syntax validation: PASSED
- Module import test: PASSED
- Linting (ruff): Minor E402 warnings (import order by design)

### Lessons Learned / Issues
- tensorflow-probability 0.25 requires TensorFlow >= 2.18, but project is pinned to TensorFlow 2.16.2
- Implemented custom `tf_percentile()` function using TensorFlow core operations instead
- Self-paced loss uses `tf.cond()` for graph-mode compatibility

### Remaining Work
- [ ] Run actual training experiments to compare BCE vs Bootstrapped BCE vs Self-paced BCE
- [ ] Tune threshold based on evaluation results
- [ ] Select final loss function
- [ ] Update documentation with best practices

### Pull Request
https://github.com/minhopark1271/trading/pull/10

### Implementation Phase Completed
2025-12-22

**Note**: 코드 구현은 완료되었으나, 손실 함수 실험 및 최종 선택은 별도 진행 필요.

